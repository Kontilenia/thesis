{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3\n",
    "!pip install langchain_aws\n",
    "!pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1cab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pydantic\n",
      "Version: 2.12.0\n",
      "Summary: Data validation using Python type hints\n",
      "Home-page: https://github.com/pydantic/pydantic\n",
      "Author: \n",
      "Author-email: Samuel Colvin <s@muelcolvin.com>, Eric Jolibois <em.jolibois@gmail.com>, Hasan Ramezani <hasan.r67@gmail.com>, Adrian Garcia Badaracco <1755071+adriangb@users.noreply.github.com>, Terrence Dorsey <terry@pydantic.dev>, David Montague <david@pydantic.dev>, Serge Matveenko <lig@countzero.co>, Marcelo Trylesinski <marcelotryle@gmail.com>, Sydney Runkle <sydneymarierunkle@gmail.com>, David Hewitt <mail@davidhewitt.io>, Alex Hall <alex.mojaki@gmail.com>, Victorien Plot <contact@vctrn.dev>, Douwe Maan <hi@douwe.me>\n",
      "License: \n",
      "Location: d:\\thesis\\thesis\\.venv\\lib\\site-packages\n",
      "Requires: annotated-types, pydantic-core, typing-extensions, typing-inspection\n",
      "Required-by: langchain-aws, langchain-core, langsmith\n"
     ]
    }
   ],
   "source": [
    "# Check pydantic verssion\n",
    "!pip show pydantic\n",
    "# Downgrading pydantic to 1.10.12\n",
    "!pip install pydantic==1.10.12 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66429c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import List\n",
    "import time\n",
    "import random\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fdb1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, json, time, random\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "class BedrockAPICalls:\n",
    "    def __init__(self, secrets_path='secrets.json', region='us-west-2',\n",
    "                 model_id='anthropic.claude-3-sonnet-20240229-v1:0'):\n",
    "        # Load secrets (optional if using IAM roles)\n",
    "        with open(secrets_path, 'r') as file:\n",
    "            secrets = json.load(file)\n",
    "            self.aws_access_key_id = secrets.get('AWS_ACCESS_KEY')\n",
    "            self.aws_secret_access_key = secrets.get('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "        session = boto3.Session(\n",
    "            aws_access_key_id=self.aws_access_key_id,\n",
    "            aws_secret_access_key=self.aws_secret_access_key,\n",
    "            region_name=region\n",
    "        )\n",
    "\n",
    "        self.model_id = model_id\n",
    "        self.client = session.client(\"bedrock-runtime\")\n",
    "\n",
    "        # Rate limiting\n",
    "        self.max_rpm = 60   # adjust to your quota\n",
    "        self.seconds_per_request = 60 / self.max_rpm\n",
    "        self._last_call_time = 0\n",
    "\n",
    "    def call_llm(self, prompt: str) -> str:\n",
    "        # Pacing\n",
    "        now = time.time()\n",
    "        elapsed = now - self._last_call_time\n",
    "        if elapsed < self.seconds_per_request:\n",
    "            time.sleep(self.seconds_per_request - elapsed)\n",
    "\n",
    "        retry_count = 0\n",
    "        while retry_count < 5:\n",
    "            try:\n",
    "\n",
    "                response = self.client.invoke_model(\n",
    "                    modelId=self.model_id,\n",
    "                    body=json.dumps({\n",
    "                        # Anthropic\n",
    "                        # \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                        # \"messages\": [{\"role\": \"user\", \n",
    "                        #               \"content\": prompt}],\n",
    "                        # \"max_tokens\": 10,\n",
    "                        # \"temperature\": 0.1\n",
    "\n",
    "                        # Llama 3.1\n",
    "                        # \"prompt\": prompt,\n",
    "                        # \"max_gen_len\": 5,\n",
    "                        # \"temperature\": 0.1\n",
    "\n",
    "                        # Mistral\n",
    "                        \"prompt\": prompt,\n",
    "                        \"max_tokens\": 10,\n",
    "                        \"temperature\": 0.1\n",
    "                    }),\n",
    "                    contentType=\"application/json\",\n",
    "                    accept=\"application/json\"\n",
    "                )\n",
    "                self._last_call_time = time.time()\n",
    "                result = json.loads(response[\"body\"].read())\n",
    "                return result #['content'][0]['text'] #['generation'] #\n",
    "            except ClientError as e:\n",
    "                if e.response['Error']['Code'] in (\"ThrottlingException\", \"TooManyRequestsException\"):\n",
    "                    wait_time = random.uniform(5, 15)\n",
    "                    print(f\"Throttled. Waiting {wait_time:.1f}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    retry_count += 1\n",
    "                else:\n",
    "                    raise\n",
    "        raise Exception(\"Max retries exceeded for Bedrock API calls.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf74c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '098400c6-725b-4c8d-82bb-010ec19447d5', 'object': 'chat.completion', 'created': 1761147417, 'model': 'mistral-large-2407', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '\\n\\nI’mgood. I’m', 'tool_calls': None, 'index': None, 'tool_call_id': None}, 'finish_reason': 'length', 'logprobs': None, 'context_logits': None, 'generation_logits': None}], 'usage': {'prompt_tokens': 5, 'total_tokens': 15, 'completion_tokens': 10}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '098400c6-725b-4c8d-82bb-010ec19447d5',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1761147417,\n",
       " 'model': 'mistral-large-2407',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': '\\n\\nI’mgood. I’m',\n",
       "    'tool_calls': None,\n",
       "    'index': None,\n",
       "    'tool_call_id': None},\n",
       "   'finish_reason': 'length',\n",
       "   'logprobs': None,\n",
       "   'context_logits': None,\n",
       "   'generation_logits': None}],\n",
       " 'usage': {'prompt_tokens': 5, 'total_tokens': 15, 'completion_tokens': 10}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = BedrockAPICalls(model_id=\"mistral.mistral-large-2407-v1:0\")\n",
    "\n",
    "prompt =  \"How are you?\"\n",
    "result = item.call_llm(prompt)\n",
    "print(result)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf0290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI’mgood. I’m'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['choices'][0]['message']['content']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
