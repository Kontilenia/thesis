{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9153802-1cbc-4419-8c75-17d64511dfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from agent_class import InformationExtractionAgent\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          Trainer,\n",
    "                          pipeline,\n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          PreTrainedTokenizer)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import huggingface_hub\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             confusion_matrix)\n",
    "from typing import List\n",
    "import wandb\n",
    "from lora_llm import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c141b57-c9af-4f2b-93d9-ec25d661a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install peft\n",
    "!pip install 'accelerate>=0.26.0'\n",
    "!pip install -U bitsandbytes\n",
    "!pip install huggingface-hub\n",
    "!pip install datasets\n",
    "!pip install langgraph\n",
    "!pip install boto3\n",
    "!pip install langchain_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb991cd6-9604-4b4c-810b-56e897c028fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read df that contain list of names and transform the column into a list object\n",
    "df = pd.read_csv('preprocessed_data/names/named_test_set_proc_final.csv', index_col=False)\n",
    "df['combined_entities'] = df['combined_entities'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "named_df = df[df['combined_entities'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "\n",
    "named_dataset = pd.read_csv('preprocessed_data/test_set_named.csv',  index_col=False)\n",
    "merged = pd.merge(named_df, named_dataset, on='Unnamed: 0', how='inner')\n",
    "unique_interview_df = merged.loc[merged.drop_duplicates(subset='interview_question').index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16b1ca-7add-47cb-a1ed-85e3bb4a01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = InformationExtractionAgent()\n",
    "buffer = []  # store all processed rows\n",
    "batch_size = 10\n",
    "\n",
    "for _, row in unique_interview_df.iterrows():\n",
    "    row_id = row[\"Unnamed: 0\"]  # adjust if your ID column name is different\n",
    "    names = row[\"combined_entities\"]\n",
    "    text = f\"{row['interview_question']} A. {row['interview_answer']}\"\n",
    "    \n",
    "    for name in names:\n",
    "        agent_results = agent.run(name=name, text=text)\n",
    "        tailored_summary = agent_results.get('tailored_summary', '')\n",
    "        \n",
    "        buffer.append({\n",
    "            \"id\": row_id,\n",
    "            \"name\": name,\n",
    "            \"status\": agent_results.get('final_state', ''),\n",
    "            \"tailored_summary\": tailored_summary\n",
    "        })\n",
    "\n",
    "        # Flush every batch_size entries for safety\n",
    "        if len(buffer) >= batch_size:\n",
    "            pd.DataFrame(buffer).to_csv('tailored_summaries2.csv', mode=\"a\", header=False, index=False)\n",
    "            buffer.clear()\n",
    "\n",
    "# Final flush for leftovers\n",
    "if buffer:\n",
    "    pd.DataFrame(buffer).to_csv('tailored_summaries2.csv', mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc131ac-4811-4358-ad29-f9db674609a4",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f9a7d5-951a-4d8d-a521-870be30f1d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>names</th>\n",
       "      <th>status</th>\n",
       "      <th>names_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Koizumi</td>\n",
       "      <td>Not matched info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Roh</td>\n",
       "      <td>Not matched info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Condi</td>\n",
       "      <td>Tailored info</td>\n",
       "      <td>Condoleezza \"Condi\" Rice was the United States...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Tailored info</td>\n",
       "      <td>Vladimir Putin is the President of Russia who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Hu Jintao</td>\n",
       "      <td>Tailored info</td>\n",
       "      <td>Hu Jintao was the President of China and leade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>301</td>\n",
       "      <td>man Boehner</td>\n",
       "      <td>No wiki entry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>304</td>\n",
       "      <td>Condi</td>\n",
       "      <td>Tailored info</td>\n",
       "      <td>\"Condi\" refers to Condoleezza Rice, who served...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>306</td>\n",
       "      <td>Don Powell</td>\n",
       "      <td>Not matched info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>306</td>\n",
       "      <td>April Ryan</td>\n",
       "      <td>Tailored info</td>\n",
       "      <td>April Ryan is a veteran White House correspond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>306</td>\n",
       "      <td>April</td>\n",
       "      <td>Not matched info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID           names            status  \\\n",
       "0      2         Koizumi  Not matched info   \n",
       "1      2             Roh  Not matched info   \n",
       "2      2           Condi     Tailored info   \n",
       "3      2  Vladimir Putin     Tailored info   \n",
       "4      2       Hu Jintao     Tailored info   \n",
       "..   ...             ...               ...   \n",
       "429  301     man Boehner     No wiki entry   \n",
       "430  304           Condi     Tailored info   \n",
       "431  306      Don Powell  Not matched info   \n",
       "432  306      April Ryan     Tailored info   \n",
       "433  306           April  Not matched info   \n",
       "\n",
       "                                     names_information  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2    Condoleezza \"Condi\" Rice was the United States...  \n",
       "3    Vladimir Putin is the President of Russia who ...  \n",
       "4    Hu Jintao was the President of China and leade...  \n",
       "..                                                 ...  \n",
       "429                                                NaN  \n",
       "430  \"Condi\" refers to Condoleezza Rice, who served...  \n",
       "431                                                NaN  \n",
       "432  April Ryan is a veteran White House correspond...  \n",
       "433                                                NaN  \n",
       "\n",
       "[434 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = pd.read_csv('tailored_summaries2.csv', index_col=False, header=None, names=[\"ID\", \"names\", \"status\", \"names_information\"])\n",
    "\n",
    "summaries[\"names_information\"] = summaries[\"names_information\"].fillna(\"\").str.strip()\n",
    "\n",
    "grouped = summaries.groupby(\"ID\")[\"names_information\"]\n",
    "\n",
    "all_empty = grouped.apply(lambda s: s.eq(\"\").all())\n",
    "any_non_empty = grouped.apply(lambda s: s.ne(\"\").any())\n",
    "\n",
    "ids_all_empty = all_empty[all_empty].index.tolist()\n",
    "ids_with_non_empty = any_non_empty[any_non_empty].index.tolist()\n",
    "\n",
    "\n",
    "# Clean up summaries (optional: remove NaN and strip whitespace)\n",
    "summaries[\"names_information\"] = summaries[\"names_information\"].fillna(\"\").str.strip()\n",
    "\n",
    "# Merge summaries for each ID into one string, separated by e.g. \"; \"\n",
    "merged = summaries.groupby(\"ID\")[\"names_information\"].agg(lambda x: \"/n \".join(s for s in x if s))\n",
    "\n",
    "\n",
    "merged.to_csv('proccessed_summaries.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('preprocessed_data/test_set_named.csv', index_col=False)\n",
    "df.rename(columns={\"Unnamed: 0\": \"ID\"}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(merged, df, on=\"ID\", how=\"inner\")\n",
    "\n",
    "final_df = merged_df[merged_df[\"ID\"].isin(ids_with_non_empty)][[\"names_information\", \"question\", \"interview_question\", \"interview_answer\", \"evasion_label\", \"clarity_label\"]]\n",
    "final_df.to_csv('named_test_set_info.csv', index=False)\n",
    "\n",
    "with open('secrets.json', 'r') as file:\n",
    "    secrets = json.load(file)\n",
    "    huggingface_hub.login(secrets.get('HF_KEY'))\n",
    "\n",
    "class_names = []\n",
    "base_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "label_name = \"evasion_label\"\n",
    "fine_tuned_model_path = f\"./llama3.1\"\n",
    "\n",
    "evaluate(base_model_name,\n",
    "         fine_tuned_model_path,\n",
    "         \"evasion_label\",\n",
    "         \"clarity_label\",\n",
    "         \"named_test_set_info.csv\",\n",
    "         False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9901a3a7-0f99-4fcc-bca1-3746ff3d08c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2d22394760492f9737a76fea22d10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "  8%|▊         | 1/13 [00:04<00:58,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: dodging \n",
      "\n",
      "### part\n",
      "Right label: dodging \n",
      "\n",
      "### explicit\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### why\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 2/13 [00:10<00:56,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: explicit \n",
      "\n",
      "### selected question\n",
      "Right label: explicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: deflection \n",
      "\n",
      "### partial\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: explicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [00:15<00:50,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: dodging \n",
      "\n",
      "### part\n",
      "Right label: dodging \n",
      "\n",
      "### explicit\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: dodging \n",
      "\n",
      "### part\n",
      "Right label: declining to answer\n",
      "Right label: general \n",
      "\n",
      "### part of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:19<00:44,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: implicit \n",
      "\n",
      "### explicit response\n",
      "Right label: implicit \n",
      "\n",
      "### part of\n",
      "Right label: deflection \n",
      "\n",
      "### selected\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: dodging \n",
      "\n",
      "### explicit\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [00:24<00:39,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### explicit\n",
      "Right label: explicit \n",
      "\n",
      "### explicit label\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: implicit \n",
      "\n",
      "### partial/h\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [00:30<00:35,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: implicit \n",
      "\n",
      "### implicit reason\n",
      "Right label: implicit \n",
      "\n",
      "### explicit label\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: implicit \n",
      "\n",
      "### explicit label\n",
      "Right label: dodging \n",
      "\n",
      "### explicit\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: explicit \n",
      "\n",
      "### selected question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 7/13 [00:35<00:31,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: explicit \n",
      "\n",
      "### why this\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: explicit \n",
      "\n",
      "### explicit response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [00:40<00:25,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: explicit \n",
      "\n",
      "### explicit label\n",
      "Right label: explicit \n",
      "\n",
      "### explicit label\n",
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: explicit \n",
      "\n",
      "### selected question\n",
      "Right label: explicit \n",
      "\n",
      "### partial/h\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9/13 [00:45<00:20,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: dodging \n",
      "\n",
      "### part\n",
      "Right label: explicit \n",
      "\n",
      "### explicit response\n",
      "Right label: explicit \n",
      "\n",
      "### partial/h\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: deflection \n",
      "\n",
      "### selected\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: explicit \n",
      "\n",
      "### partial/h\n",
      "Right label: dodging \n",
      "\n",
      "### explicit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [00:50<00:15,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: deflection \n",
      "\n",
      "### partial\n",
      "Right label: dodging \n",
      "\n",
      "### explicit\n",
      "Right label: implicit \n",
      "\n",
      " \n",
      "\n",
      "the response\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: implicit \n",
      "\n",
      "### why this\n",
      "Right label: explicit \n",
      "\n",
      "### partial/\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:55<00:10,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: deflection \n",
      "\n",
      "### part\n",
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: explicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "reason:\n",
      "Right label: explicit \n",
      "\n",
      "### partial/h\n",
      "Right label: explicit \n",
      "\n",
      "### partial/h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12/13 [01:00<00:05,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: dodging \n",
      "\n",
      "### partial\n",
      "Right label: dodging \n",
      "\n",
      "### selected\n",
      "Right label: explicit \n",
      "\n",
      "### explicit label\n",
      "Right label: implicit \n",
      "\n",
      "### implicit reason\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n",
      "Right label: implicit \n",
      "\n",
      "### selected question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:01<00:00,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right label: explicit \n",
      "\n",
      "### part of\n",
      "----\n",
      "0         indirect\n",
      "1         indirect\n",
      "2         indirect\n",
      "3         indirect\n",
      "4         indirect\n",
      "          ...     \n",
      "92    direct reply\n",
      "93        indirect\n",
      "94        indirect\n",
      "95        indirect\n",
      "96    direct reply\n",
      "Name: clarity_label, Length: 97, dtype: object\n",
      "----\n",
      "----\n",
      "0          indirect\n",
      "1          indirect\n",
      "2          indirect\n",
      "3          indirect\n",
      "4          indirect\n",
      "           ...     \n",
      "102        indirect\n",
      "103    direct reply\n",
      "105        indirect\n",
      "106        indirect\n",
      "107        indirect\n",
      "Name: clarity_label, Length: 97, dtype: object\n",
      "----\n",
      "['indirect', 'direct reply', 'direct non-reply']\n",
      "Accuracy: 0.65\n",
      "Accuracy for label indirect: 0.72\n",
      "Accuracy for label direct reply: 0.57\n",
      "Accuracy for label direct non-reply: 0.00\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        indirect       0.74      0.72      0.73        64\n",
      "    direct_reply       0.50      0.57      0.53        30\n",
      "direct_non-reply       0.00      0.00      0.00         3\n",
      "\n",
      "       micro avg       0.66      0.65      0.65        97\n",
      "       macro avg       0.41      0.43      0.42        97\n",
      "    weighted avg       0.64      0.65      0.65        97\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[46 17  0]\n",
      " [13 17  0]\n",
      " [ 3  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Load unproccesed summaries data\n",
    "summaries_df = pd.read_csv(\n",
    "    'tailored_summaries2.csv',\n",
    "    index_col=False,\n",
    "    header=None,\n",
    "    names=[\"ID\", \"names\", \"status\", \"names_information\"]\n",
    ")\n",
    "\n",
    "# Remove NaN and strip whitespace from summaries and group by ID\n",
    "summaries_df[\"names_information\"] = summaries_df[\"names_information\"].fillna(\"\").str.strip()\n",
    "grouped_summaries = summaries_df.groupby(\"ID\")[\"names_information\"]\n",
    "\n",
    "# Find if grouped summaries for an ID is non-empty and extract lists of IDs\n",
    "any_non_empty_mask = grouped_summaries.apply(lambda s: s.ne(\"\").any())\n",
    "ids_with_non_empty = any_non_empty_mask[any_non_empty_mask].index.tolist()\n",
    "\n",
    "# Merge summaries for each ID into one string\n",
    "merged_summaries_df = summaries_df.groupby(\"ID\")[\"names_information\"] \\\n",
    "    .agg(lambda x: \"\\n\".join(s for s in x if s))\n",
    "\n",
    "merged_summaries_df.to_csv('processed_summaries.csv', index=False)\n",
    "\n",
    "# Load test set and merge with summaries\n",
    "named_test_set_df = pd.read_csv('preprocessed_data/test_set_named.csv', index_col=False)\n",
    "named_test_set_df.rename(columns={\"Unnamed: 0\": \"ID\"}, inplace=True)\n",
    "rag_test_df = pd.merge(merged_summaries_df, named_test_set_df, on=\"ID\", how=\"inner\")\n",
    "\n",
    "# Filter to only IDs with at least one non-empty summary\n",
    "rag_test_df = rag_test_df[\n",
    "    rag_test_df[\"ID\"].isin(ids_with_non_empty)\n",
    "][[\n",
    "    \"names_information\",\n",
    "    \"question\",\n",
    "    \"interview_question\",\n",
    "    \"interview_answer\",\n",
    "    \"evasion_label\",\n",
    "    \"clarity_label\"\n",
    "]]\n",
    "\n",
    "rag_test_df.to_csv('named_test_set_info.csv', index=False)\n",
    "\n",
    "# Test RAG results\n",
    "with open('secrets.json', 'r') as file:\n",
    "    secrets = json.load(file)\n",
    "    huggingface_hub.login(secrets.get('HF_KEY'))\n",
    "\n",
    "class_names = []\n",
    "base_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "label_name = \"evasion_label\"\n",
    "fine_tuned_model_path = \"./llama3.1\"\n",
    "\n",
    "evaluate(\n",
    "    base_model_name,\n",
    "    fine_tuned_model_path,\n",
    "    \"evasion_label\",\n",
    "    \"clarity_label\",\n",
    "    \"named_test_set_info.csv\",\n",
    "    False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
