{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForCausalLM,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline)\n",
    "import torch\n",
    "from peft import LoraConfig\n",
    "import huggingface_hub\n",
    "import pandas as pd\n",
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'accelerate>=0.26.0'\n",
    "!pip install -U bitsandbytes\n",
    "!pip install trl\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install peft\n",
    "!pip install torch\n",
    "!pip install huggingface-hub\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompted_text(\n",
    "    dataset,\n",
    "    label_name,\n",
    "):\n",
    "    texts = []\n",
    "    classes_names = ', '.join(list(dataset[label_name].unique()))\n",
    "\n",
    "    for _, row in dataset.iterrows():\n",
    "        texts.append(\n",
    "            f\"You will be given a part of an interview.\"\n",
    "            f\"Classify the response to the selected question\"\n",
    "            f\"into one of the following categories: {classes_names}\"\n",
    "            f\". \\n\\n ### Part of the interview ### \\nIntervier:\"\n",
    "            f\" {row['interview_question']} \\nResponse:\"\n",
    "            f\" {row['interview_answer']} \\n\\n### Selected Question ###\\n\"\n",
    "            f\"{row['question']} \\n\\nLabel:\"\n",
    "        )\n",
    "    return texts\n",
    "\n",
    "\n",
    "def predict(test, categories, model, tokenizer):\n",
    "\n",
    "    # Set logging level to ERROR to suppress INFO messages\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "    y_pred = []\n",
    "    pipe = pipeline(task=\"text-generation\",\n",
    "                    model=model,\n",
    "                    tokenizer=tokenizer,\n",
    "                    # max_new_tokens=4\n",
    "                    )\n",
    "\n",
    "    for i in tqdm(range(len(test))):\n",
    "        prompt = test.iloc[i][\"text\"]\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['generated_text'].split(\"Label:\")[-1].strip()\n",
    "\n",
    "        # Determine the predicted category\n",
    "        for category in categories:\n",
    "            if category.lower() in answer.lower():\n",
    "                print(\"Right label:\" + answer.lower())\n",
    "                y_pred.append(category)\n",
    "                break\n",
    "        else:\n",
    "            print(\"Wrong label:\" + answer.lower())\n",
    "            y_pred.append(\"none\")\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluation_report(y_true, y_pred, labels, run=None):\n",
    "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, -1)  # Map to -1 if not found\n",
    "\n",
    "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "\n",
    "    if run:\n",
    "        wandb_log_dict = {}\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    if run:\n",
    "        wandb_log_dict[\"Accuracy\"] = accuracy\n",
    "\n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true_mapped)  # Get unique labels\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true_mapped))\n",
    "                         if y_true_mapped[i] == label]\n",
    "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {labels[label]}: {label_accuracy:.2f}')\n",
    "        if run:\n",
    "            wandb_log_dict[f\"Accuracy for label {labels[label]}\"] = label_accuracy\n",
    "\n",
    "    unsplit_labels = [label.replace(\" \", \"_\") for label in labels]\n",
    "\n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true_mapped,\n",
    "                                         y_pred=y_pred_mapped,\n",
    "                                         target_names=unsplit_labels,\n",
    "                                         labels=list(range(len(labels))))\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "    report_columns = [\"Class\", \"Precision\", \"Recall\", \"F1-score\", \"Support\"]\n",
    "    report_table = []\n",
    "    class_report = class_report.splitlines()\n",
    "    for line in class_report[2:(len(labels)+2)]:\n",
    "        report_table.append(line.split())\n",
    "\n",
    "    if run:\n",
    "        wandb_log_dict[\"Classification Report\"] = wandb.Table(\n",
    "            data=report_table,\n",
    "            columns=report_columns)\n",
    "\n",
    "    # For not predicted classes\n",
    "    mask = y_pred_mapped != -1\n",
    "    y_true_mapped2 = y_true_mapped[mask]\n",
    "    y_pred_mapped2 = y_pred_mapped[mask]\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true_mapped,\n",
    "                                   y_pred=y_pred_mapped,\n",
    "                                   labels=list(range(len(labels))))\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n",
    "    if run:\n",
    "        wandb_log_dict[\"Confusion Matix\"] = wandb.plot.confusion_matrix(\n",
    "            y_true=y_true_mapped2,\n",
    "            preds=y_pred_mapped2,\n",
    "            class_names=labels\n",
    "        )\n",
    "        run.log(wandb_log_dict)\n",
    "\n",
    "\n",
    "def evaluate(base_model_name, fine_tuned_model_path, label_name, run=None):\n",
    "\n",
    "    cache_dir = \"\"\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        return_dict=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        ),\n",
    "        # torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        offload_folder=\"offload/\",\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name,\n",
    "                                              cache_dir=cache_dir)\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "    # Get test set data\n",
    "    test_df = pd.read_csv('preprocessed_data/test_set.csv')[[\n",
    "        'question',\n",
    "        'interview_question',\n",
    "        'interview_answer',\n",
    "        label_name\n",
    "    ]]\n",
    "\n",
    "    test_texts = create_test_prompted_text(test_df, label_name)\n",
    "    dataset = pd.DataFrame(test_texts, columns=['text'])\n",
    "\n",
    "    labels = list(test_df[label_name].unique())\n",
    "\n",
    "    y_pred = predict(dataset, labels, model, tokenizer)\n",
    "    y_true = test_df[label_name]\n",
    "    evaluation_report(y_true, y_pred, labels, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "df = pd.read_csv('preprocessed_data/train_set.csv').iloc[:100]\n",
    "df.rename(columns={'evasion_label': 'label'}, inplace=True)\n",
    "df.drop(columns=['clarity_label'], inplace=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Define the quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    # bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Define the Lora config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    # target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "huggingface_hub.login(os.environ[\"HF_KEY\"])\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token # Set the pad token to eos token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "classes_names = ', '.join(list(df['label'].unique()))\n",
    "\n",
    "\n",
    "def format_func(\n",
    "    dataset\n",
    "):\n",
    "    text = (\n",
    "        f\"You will be given a part of an interview. \"\n",
    "        f\"Classify the response to the selected question \"\n",
    "        f\"into one of the following categories: {classes_names}\"\n",
    "        f\". \\n\\n ### Part of the interview ### \\nInterviewer:\"\n",
    "        f\" {dataset['interview_question']} \\nResponse:\"\n",
    "        f\" {dataset['interview_answer']} \\n\\n### Selected Question ###\\n\"\n",
    "        f\"{dataset['question']} \\n\\n### Label: {dataset['label']}\"\n",
    "    )\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "response_template = \"### Label:\"\n",
    "response_template_ids = tokenizer.encode(response_template, add_special_tokens=False)[2:]\n",
    "collator = DataCollatorForCompletionOnlyLM(tokenizer=tokenizer, response_template=response_template_ids)\n",
    "\n",
    "fine_tuned_model_path = \"./llama3.1\"\n",
    "lr = 2e-4\n",
    "epochs = 5\n",
    "base_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "\n",
    "# Wandb configuration\n",
    "run = wandb.init(entity=\"kontilenia-national-technical-university-of-athens\",\n",
    "                 project='political-speech-clarity',\n",
    "                 job_type=\"training\",\n",
    "                 # Track hyperparameters and run metadata\n",
    "                 config={\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"architecture\": base_model_name,\n",
    "                    \"dataset\": \"qevasion_dataset_preproccessed\",\n",
    "                    \"epochs\": epochs,\n",
    "                 })\n",
    "\n",
    "# Create the trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=1,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        label_names=classes_names,\n",
    "    ),\n",
    "    formatting_func=format_func,\n",
    "    data_collator=collator,\n",
    "    peft_config=lora_config,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "fine_tuned_model_path = \"./llama3.1\"\n",
    "model.save_pretrained(fine_tuned_model_path)\n",
    "\n",
    "base_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "label_name = \"clarity_label\"\n",
    "evaluate(base_model_name,\n",
    "         fine_tuned_model_path,\n",
    "         label_name,\n",
    "         run)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN5n1KZofVGTZFVLtQb7p3Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
