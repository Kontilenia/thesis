{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7fa1b3-4729-4ef9-bb48-af5fe50575ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from peft import PeftModel\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0e0dc-bb03-41eb-920b-0706f0204810",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install peft\n",
    "!pip install transformers\n",
    "!pip install einops\n",
    "!pip install sentencepiece\n",
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a578c0-a2de-478d-8b6d-ec862e255d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/home/ec2-user/SageMaker\"\n",
    "os.environ['HF_HOME'] = cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6fecf-a062-4b67-ac0f-36247ee728be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, size: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a given text into smaller chunks of a specified size.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be chunked.\n",
    "        size (int): The maximum size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list containing text chunks.\n",
    "    \"\"\"\n",
    "    return [text[i:i+size] for i in range(0, len(text), size)]\n",
    "\n",
    "\n",
    "def extract_names(text: str,\n",
    "                  tokenizer: AutoTokenizer,\n",
    "                  model: torch.nn.Module,\n",
    "                  chunk_size: int = 1000) -> str:\n",
    "    \"\"\"\n",
    "    Extracts person names from the input text using a language model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing potential person names.\n",
    "        tokenizer (AutoTokenizer): Tokenizer associated with the language\n",
    "        model.\n",
    "        model (torch.nn.Module): The fine-tuned language model used for name\n",
    "        extraction.\n",
    "        chunk_size (int, optional): Maximum characters per chunk for processing.\n",
    "        Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        str: Concatenated string of recognized person names and entities.\n",
    "    \"\"\"\n",
    "    chunks = chunk_text(text, chunk_size)\n",
    "    all_names = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        prompt = (\n",
    "            # \"Recognize all people names in the following text. \"\n",
    "            # \"Format the answer as: person name: entity; person name: entity. \\n\\n\"\n",
    "            \"Recognize all politically invlolved names in the text.\"\n",
    "            \"Return the names of the entities as a list, without duplicates.\\n\"\n",
    "            \"The answer format should be \\\"person: entity's name; person: entity's name\\\"\"\n",
    "            f\"Text: {chunk} \\nAnswer:\"\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            [prompt],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                use_cache=False\n",
    "            )\n",
    "\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        response = generated_text.split(\"Answer:\")[-1].strip()\n",
    "        all_names.append(response)\n",
    "\n",
    "    return \"; \".join(all_names).strip()\n",
    "\n",
    "\n",
    "def recognise_names(df: pd.DataFrame,\n",
    "                    new_column_name: str = \"recognized_names\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recognizes person names from interview questions and answers using a\n",
    "    fine-tuned LLM.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'interview_question'\n",
    "        and 'interview_answer'.\n",
    "        new_column_name (str, optional): Name of the new column to store\n",
    "        recognized names. Defaults to 'recognized_names'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with an additional\n",
    "        column of recognized names.\n",
    "    \"\"\"\n",
    "    base_model_path = \"internlm/internlm2_5-7b\"\n",
    "    lora_path = \"Umean/B2NER-Internlm2.5-7B-LoRA\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_path,\n",
    "                                              trust_remote_code=True,\n",
    "                                              cache_dir=cache_dir)\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "\n",
    "    model = PeftModel.from_pretrained(\n",
    "        base_model, lora_path, torch_dtype=torch.float16, device_map=\"auto\"\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    unique_pairs = df[[\"interview_question\", \"interview_answer\"]].drop_duplicates()\n",
    "\n",
    "    names_map = {}\n",
    "    for _, row in tqdm(unique_pairs.iterrows(),\n",
    "                       total=len(unique_pairs),\n",
    "                       desc=\"Extracting Names\"):\n",
    "        key = row[\"interview_question\"]\n",
    "        text = str(row[\"interview_question\"] + row[\"interview_answer\"])\n",
    "        names_map[key] = extract_names(text, tokenizer, model)\n",
    "\n",
    "    df[new_column_name] = df[\"interview_question\"].map(names_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c99fef-3c94-4744-af98-8a7672990eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('preprocessed_data/test_set.csv')\n",
    "recognise_names(test_df, \"recognised_names\")\n",
    "\n",
    "file_path = \"./preprocessed_data/names/named_test_set2.csv\"\n",
    "test_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0109fd8-3fd4-4b50-8e9a-cbb868e293ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('preprocessed_data/names/named_test_set1.csv')[\"recognised_names\"]\n",
    "df1 = df1.str.replace(r'None;?|None', '', regex=True)\n",
    "df1 = df1.str.replace(r'None', '', regex=True)\n",
    "df1 = df1.str.replace(r'person:', '', regex=True)\n",
    "df1 = df1.str.replace(r's name:', '', regex=True)\n",
    "df1 = df1.str.replace(r'entity:', '', regex=True)\n",
    "df1 = df1.str.replace(r'entity;?|', '', regex=True)\n",
    "df1 = df1.str.replace(r',', ';', regex=True)\n",
    "df1 = df1.str.replace(r'Mr. President;?', '', regex=True)\n",
    "df1 = df1.str.replace(r'President;?', '', regex=True)\n",
    "df1 = df1.str.replace(r'Mr. Prime Minister;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime Minister', '', regex=True)\n",
    "df1 = df1.str.replace(r'person;?|', '', regex=True)\n",
    "df1 = df1.str.replace(r'person', '', regex=True)\n",
    "df1 = df1.str.replace(r'skeptics;', '', regex=True)\n",
    "df1 = df1.str.replace(r'leaders;', '', regex=True)\n",
    "df1 = df1.str.replace(r'person', '', regex=True)\n",
    "df1 = df1.str.replace(r'Kevin Corke', '', regex=True)\n",
    "df1 = df1.str.replace(r'Jessica', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime;', '', regex=True)\n",
    "df1 = df1.str.replace(r'R;', '', regex=True)\n",
    "df1 = df1.str.replace(r'so-and-so;', '', regex=True)\n",
    "df1 = df1.str.replace(r'ial;', '', regex=True)\n",
    "df1 = df1.str.replace(r'dad;', '', regex=True)\n",
    "df1 = df1.str.replace(r'father', '', regex=True)\n",
    "df1 = df1.str.replace(r' ted;', '', regex=True)\n",
    "df1 = df1.str.replace(r'so-and-so;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Lebanese', '', regex=True)\n",
    "df1 = df1.str.replace(r'Government', '', regex=True)\n",
    "df1 = df1.str.replace(r'Democrats', '', regex=True)\n",
    "df1 = df1.str.replace(r'Republican leader', '', regex=True)\n",
    "df1 = df1.str.replace(r'American people', '', regex=True)\n",
    "df1 = df1.str.replace(r'American s;', '', regex=True)\n",
    "df1 = df1.str.replace(r'ian people;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Israel;', '', regex=True)\n",
    "df1 = df1.str.replace(r'of the United States;', '', regex=True)\n",
    "df1 = df1.str.replace(r'of Lebanon', '', regex=True)\n",
    "df1 = df1.str.replace(r'Lebanon', '', regex=True)\n",
    "df1 = df1.str.replace(r'Congress', '', regex=True)\n",
    "df1 = df1.str.replace(r'Presid', '', regex=True)\n",
    "df1 = df1.str.replace(r' C;', '', regex=True)\n",
    "df1 = df1.str.replace(r' U.S.;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Secretaries of Defence', '', regex=True)\n",
    "df1 = df1.str.replace(r'National Security Advisers;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Republican chairman;', '', regex=True)\n",
    "df1 = df1.str.replace(r'administration', '', regex=True)\n",
    "df1 = df1.str.replace(r'bipartisan', '', regex=True)\n",
    "df1 = df1.str.replace(r'-elect', '', regex=True)\n",
    "df1 = df1.str.replace(r'Senators', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime Minister;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Cuban people;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Cuban exiles;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Cuban;', '', regex=True)\n",
    "df1 = df1.str.replace(r'U.N.;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Trade Minister;', '', regex=True)\n",
    "df1 = df1.str.replace(r'U.S. Trade Representative', '', regex=True)\n",
    "df1 = df1.str.replace(r'Americans', '', regex=True)\n",
    "df1 = df1.str.replace(r'local', '', regex=True)\n",
    "df1 = df1.str.replace(r'American citizens;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Border Patrol agent;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Member of', '', regex=True)\n",
    "df1 = df1.str.replace(r'Defence Secretary;', '', regex=True)\n",
    "df1 = df1.str.replace(r'FDA Commissioner', '', regex=True)\n",
    "df1 = df1.str.replace(r'Ambassador;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Saddamists;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Palestinians;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Israelis;', '', regex=True)\n",
    "df1 = df1.str.replace(r'nian citizens;', '', regex=True)\n",
    "df1 = df1.str.replace(r'seniors;', '', regex=True)\n",
    "df1 = df1.str.replace(r'marks;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Secretary of State', '', regex=True)\n",
    "df1 = df1.str.replace(r'NATO;', '', regex=True)\n",
    "df1 = df1.str.replace(r'lks', '', regex=True)\n",
    "df1 = df1.str.replace(r'Social Security', '', regex=True)\n",
    "df1 = df1.str.replace(r'House Republicans', '', regex=True)\n",
    "df1 = df1.str.replace(r'terrorists', '', regex=True)\n",
    "df1 = df1.str.replace(r'extremists', '', regex=True)\n",
    "df1 = df1.str.replace(r'foreign', '', regex=True)\n",
    "df1 = df1.str.replace(r'mother', '', regex=True)\n",
    "df1 = df1.str.replace(r'Home Secretary', '', regex=True)\n",
    "df1 = df1.str.replace(r'children', '', regex=True)\n",
    "df1 = df1.str.replace(r'Iraq', '', regex=True)\n",
    "df1 = df1.str.replace(r'Afghanistan', '', regex=True)\n",
    "df1 = df1.str.replace(r'enemy', '', regex=True)\n",
    "df1 = df1.str.replace(r'allies', '', regex=True)\n",
    "df1 = df1.str.replace(r'Commander in Chief', '', regex=True)\n",
    "df1 = df1.str.replace(r'American;', '', regex=True)\n",
    "df1 = df1.str.replace(r'European political leadership', '', regex=True)\n",
    "df1 = df1.str.replace(r'tribal chiefs', '', regex=True)\n",
    "df1 = df1.str.replace(r'i people', '', regex=True)\n",
    "df1 = df1.str.replace(r'Al Qaida', '', regex=True)\n",
    "df1 = df1.str.replace(r'Jerusalem', '', regex=True)\n",
    "df1 = df1.str.replace(r', Israelis, America, Britain, Palestinians, Palestinian', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Jackson;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Helen Thomas', '', regex=True)\n",
    "df1 = df1.str.replace(r'Mike Emanuel', '', regex=True)\n",
    "df1 = df1.str.replace(r'Terry', '', regex=True)\n",
    "df1 = df1.str.replace(r'Mr.', '', regex=True)\n",
    "df1 = df1.str.replace(r'Illinois National Guardsmen', '', regex=True)\n",
    "df1 = df1.str.replace(r'Taliban', '', regex=True)\n",
    "df1 = df1.str.replace(r'Israeli soldiers', '', regex=True)\n",
    "df1 = df1.str.replace(r'American Urban Radio Networks', '', regex=True)\n",
    "df1 = df1.str.replace(r'Iran', '', regex=True)\n",
    "df1 = df1.str.replace(r'Russia', '', regex=True)\n",
    "df1 = df1.str.replace(r'Members of', '', regex=True)\n",
    "df1 = df1.str.replace(r'South', '', regex=True)\n",
    "df1 = df1.str.replace(r\"; 's;\", \";\", regex=True)\n",
    "df1 = df1.str.replace(r\"';\", \";\", regex=True)\n",
    "df1 = df1.str.replace(r\"'\", \" \", regex=True)\n",
    "df1 = df1.str.replace(r'medical experts', '', regex=True)\n",
    "df1 = df1.str.replace(r'Defense Secretary', '', regex=True)\n",
    "df1 = df1.str.replace(r'Soviet', '', regex=True)\n",
    "df1 = df1.str.replace(r'America', '', regex=True)\n",
    "df1 = df1.str.replace(r'Republicans', '', regex=True)\n",
    "df1 = df1.str.replace(r'Arab', '', regex=True)\n",
    "df1 = df1.str.replace(r'Pakistan', '', regex=True)\n",
    "df1 = df1.str.replace(r'Syria', '', regex=True)\n",
    "\n",
    "df1.replace(r'^\\s+$', np.nan, regex=True, inplace=True)\n",
    "print(df1.count())\n",
    "df1.to_csv('preprocessed_data/names/named_test_set_proc1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b2bfe6-2e17-4a7e-9dad-961e013184c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('preprocessed_data/names/named_test_set2.csv')[\"recognised_names\"]\n",
    "df1 = df1.str.replace(r'None;?|None', '', regex=True)\n",
    "df1 = df1.str.replace(r'None', '', regex=True)\n",
    "df1 = df1.str.replace(r'person:', '', regex=True)\n",
    "df1 = df1.str.replace(r's name:', '', regex=True)\n",
    "df1 = df1.str.replace(r'entity:', '', regex=True)\n",
    "df1 = df1.str.replace(r'entity;?|', '', regex=True)\n",
    "df1 = df1.str.replace(r',', ';', regex=True)\n",
    "df1 = df1.str.replace(r'Mr. President;?', '', regex=True)\n",
    "df1 = df1.str.replace(r'President;?', '', regex=True)\n",
    "df1 = df1.str.replace(r'Mr. Prime Minister;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime Minister;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime Minister', '', regex=True)\n",
    "df1 = df1.str.replace(r'person;?|', '', regex=True)\n",
    "df1 = df1.str.replace(r'person', '', regex=True)\n",
    "df1 = df1.str.replace(r'skeptics;', '', regex=True)\n",
    "df1 = df1.str.replace(r'leaders;', '', regex=True)\n",
    "df1 = df1.str.replace(r'person', '', regex=True)\n",
    "df1 = df1.str.replace(r'Kevin Corke', '', regex=True)\n",
    "df1 = df1.str.replace(r'Jessica', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime;', '', regex=True)\n",
    "df1 = df1.str.replace(r'R;', '', regex=True)\n",
    "df1 = df1.str.replace(r'so-and-so;', '', regex=True)\n",
    "df1 = df1.str.replace(r'ial;', '', regex=True)\n",
    "df1 = df1.str.replace(r'dad;', '', regex=True)\n",
    "df1 = df1.str.replace(r'father', '', regex=True)\n",
    "df1 = df1.str.replace(r' ted;', '', regex=True)\n",
    "df1 = df1.str.replace(r'so-and-so;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Lebanese', '', regex=True)\n",
    "df1 = df1.str.replace(r'Government', '', regex=True)\n",
    "df1 = df1.str.replace(r'Democrats', '', regex=True)\n",
    "df1 = df1.str.replace(r'Republican leader', '', regex=True)\n",
    "df1 = df1.str.replace(r'American people', '', regex=True)\n",
    "df1 = df1.str.replace(r'American s;', '', regex=True)\n",
    "df1 = df1.str.replace(r'ian people;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Israel;', '', regex=True)\n",
    "df1 = df1.str.replace(r'of the United States;', '', regex=True)\n",
    "df1 = df1.str.replace(r'of Lebanon', '', regex=True)\n",
    "df1 = df1.str.replace(r'Lebanon', '', regex=True)\n",
    "df1 = df1.str.replace(r'Congress', '', regex=True)\n",
    "df1 = df1.str.replace(r'Presid', '', regex=True)\n",
    "df1 = df1.str.replace(r' C;', '', regex=True)\n",
    "df1 = df1.str.replace(r' U.S.;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Secretaries of Defence', '', regex=True)\n",
    "df1 = df1.str.replace(r'National Security Advisers;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Republican chairman;', '', regex=True)\n",
    "df1 = df1.str.replace(r'administration', '', regex=True)\n",
    "df1 = df1.str.replace(r'bipartisan', '', regex=True)\n",
    "df1 = df1.str.replace(r'-elect', '', regex=True)\n",
    "df1 = df1.str.replace(r'Senators', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime Minister;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Cuban people;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Cuban exiles;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Cuban;', '', regex=True)\n",
    "df1 = df1.str.replace(r'U.N.;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Trade Minister;', '', regex=True)\n",
    "df1 = df1.str.replace(r'U.S. Trade Representative', '', regex=True)\n",
    "df1 = df1.str.replace(r'Americans', '', regex=True)\n",
    "df1 = df1.str.replace(r'local', '', regex=True)\n",
    "df1 = df1.str.replace(r'American citizens;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Border Patrol agent;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Member of', '', regex=True)\n",
    "df1 = df1.str.replace(r'Defence Secretary;', '', regex=True)\n",
    "df1 = df1.str.replace(r'FDA Commissioner', '', regex=True)\n",
    "df1 = df1.str.replace(r'Ambassador;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Saddamists;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Palestinians;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Israelis;', '', regex=True)\n",
    "df1 = df1.str.replace(r'nian citizens;', '', regex=True)\n",
    "df1 = df1.str.replace(r'seniors;', '', regex=True)\n",
    "df1 = df1.str.replace(r'marks;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Secretary of State', '', regex=True)\n",
    "df1 = df1.str.replace(r'NATO;', '', regex=True)\n",
    "df1 = df1.str.replace(r'lks', '', regex=True)\n",
    "df1 = df1.str.replace(r'Social Security', '', regex=True)\n",
    "df1 = df1.str.replace(r'House Republicans', '', regex=True)\n",
    "df1 = df1.str.replace(r'terrorists', '', regex=True)\n",
    "df1 = df1.str.replace(r'extremists', '', regex=True)\n",
    "df1 = df1.str.replace(r'foreign', '', regex=True)\n",
    "df1 = df1.str.replace(r'mother', '', regex=True)\n",
    "df1 = df1.str.replace(r'Home Secretary', '', regex=True)\n",
    "df1 = df1.str.replace(r'children', '', regex=True)\n",
    "df1 = df1.str.replace(r'Iraq', '', regex=True)\n",
    "df1 = df1.str.replace(r'Afghanistan', '', regex=True)\n",
    "df1 = df1.str.replace(r'enemy', '', regex=True)\n",
    "df1 = df1.str.replace(r'allies', '', regex=True)\n",
    "df1 = df1.str.replace(r'Commander in Chief', '', regex=True)\n",
    "df1 = df1.str.replace(r'American;', '', regex=True)\n",
    "df1 = df1.str.replace(r'European political leadership', '', regex=True)\n",
    "df1 = df1.str.replace(r'tribal chiefs', '', regex=True)\n",
    "df1 = df1.str.replace(r'i people', '', regex=True)\n",
    "df1 = df1.str.replace(r'Al Qaida', '', regex=True)\n",
    "df1 = df1.str.replace(r'Jerusalem', '', regex=True)\n",
    "df1 = df1.str.replace(r', Israelis, America, Britain, Palestinians, Palestinian', '', regex=True)\n",
    "df1 = df1.str.replace(r'Prime;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Jackson;', '', regex=True)\n",
    "df1 = df1.str.replace(r'Helen Thomas', '', regex=True)\n",
    "df1 = df1.str.replace(r'Mike Emanuel', '', regex=True)\n",
    "df1 = df1.str.replace(r'Terry', '', regex=True)\n",
    "df1 = df1.str.replace(r'Mr.', '', regex=True)\n",
    "df1 = df1.str.replace(r'Illinois National Guardsmen', '', regex=True)\n",
    "df1 = df1.str.replace(r'Taliban', '', regex=True)\n",
    "df1 = df1.str.replace(r'Israeli soldiers', '', regex=True)\n",
    "df1 = df1.str.replace(r'American Urban Radio Networks', '', regex=True)\n",
    "df1 = df1.str.replace(r'Iran', '', regex=True)\n",
    "df1 = df1.str.replace(r'Russia', '', regex=True)\n",
    "df1 = df1.str.replace(r'Members of', '', regex=True)\n",
    "df1 = df1.str.replace(r'South', '', regex=True)\n",
    "df1 = df1.str.replace(r\"; 's;\", \";\", regex=True)\n",
    "df1 = df1.str.replace(r\"';\", \";\", regex=True)\n",
    "df1 = df1.str.replace(r\"'\", \" \", regex=True)\n",
    "df1 = df1.str.replace(r'medical experts', '', regex=True)\n",
    "df1 = df1.str.replace(r'Defense Secretary', '', regex=True)\n",
    "df1 = df1.str.replace(r'Soviet', '', regex=True)\n",
    "df1 = df1.str.replace(r'America', '', regex=True)\n",
    "df1 = df1.str.replace(r'Republicans', '', regex=True)\n",
    "df1 = df1.str.replace(r'Arab', '', regex=True)\n",
    "df1 = df1.str.replace(r'Pakistan', '', regex=True)\n",
    "df1 = df1.str.replace(r'Syria', '', regex=True)\n",
    "\n",
    "df1.replace(r'^\\s+$', np.nan, regex=True, inplace=True)\n",
    "print(df1.count())\n",
    "df1.to_csv('preprocessed_data/names/named_test_set_proc2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15fa19f-178e-404c-9002-bd5f46907cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('preprocessed_data/names/named_test_set_proc1.csv')\n",
    "df2 = pd.read_csv('preprocessed_data/names/named_test_set_proc2.csv')\n",
    "\n",
    "def clean_and_split(s):\n",
    "    if pd.isna(s) or not s.strip():\n",
    "        return []\n",
    "    return [item.strip() for item in s.split(';') if item.strip()]\n",
    "\n",
    "\n",
    "def merge_row(row):\n",
    "    combined = clean_and_split(row['df1']) + clean_and_split(row['df2'])\n",
    "    return list(set(combined))\n",
    "\n",
    "# Assuming df1 and df2 have one column each named 'names'\n",
    "df_combined = pd.DataFrame({\n",
    "    'df1': df1.iloc[:, 1],\n",
    "    'df2': df2.iloc[:, 1]\n",
    "})\n",
    "\n",
    "df_combined['combined_entities'] = df_combined.apply(merge_row, axis=1)\n",
    "df_combined = df_combined['combined_entities']\n",
    "df_combined.to_csv('preprocessed_data/names/named_test_set_proc_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac7b6ce-52aa-472c-b53b-0ce7685f40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df1 = pd.read_csv('preprocessed_data/names/named_test_set_proc_final.csv')\n",
    "df2 = pd.read_csv('preprocessed_data/test_set.csv')\n",
    "\n",
    "# Convert stringified lists to actual Python lists\n",
    "df1['combined_entities'] = df1['combined_entities'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "\n",
    "# filtered_df = df1[df1['combined_entities'].apply(lambda x: x != [])]\n",
    "named_df = df2[df1['combined_entities'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "named_df.to_csv('preprocessed_data/test_set_named.csv')\n",
    "unnamed_df = df2[df1['combined_entities'].apply(lambda x: isinstance(x, list) and len(x) == 0)]\n",
    "unnamed_df.to_csv('preprocessed_data/test_set_unnamed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e39e2-8704-4859-87f5-2f1854e0dd86",
   "metadata": {},
   "source": [
    "**Check names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902f642-1464-4838-9d58-0c8360a30cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3759bcb2-a0c5-4ea5-b1a5-77996ebca529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of names that are politically involved, without duplicates:\n",
      "\n",
      "[Putin, Condi, Siniora, Senitor Warner, Taliban]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Set up AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='',\n",
    "    aws_secret_access_key='',\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "\n",
    "# Create a Bedrock client\n",
    "bedrock = session.client('bedrock-runtime')\n",
    "\n",
    "# Claude 3 Haiku model ID\n",
    "model_id = 'anthropic.claude-3-opus-20240229-v1:0'\n",
    "\n",
    "# Messages API format with required version\n",
    "body = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"This is a list. Identify only the people names that are politically invlolved and return a list with only those names without dublicates: [Putin, Vladimir, John, pedophile, adios, Condi, Siniora, Senitor Warner, Taliban]\"}\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "}\n",
    "\n",
    "# Call Claude 3 using Messages API\n",
    "response = bedrock.invoke_model(\n",
    "    modelId=model_id,\n",
    "    contentType='application/json',\n",
    "    accept='application/json',\n",
    "    body=json.dumps(body)\n",
    ")\n",
    "\n",
    "result = json.loads(response['body'].read().decode())['content'][0]['text']\n",
    "# Read and decode response\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bae8258-2d1b-4ab8-86a6-c8e0acbd931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the anthropic library\n",
    "!pip install anthropic\n",
    "\n",
    "import anthropic\n",
    "\n",
    "# Initialize the Anthropics client\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "def is_person_name(entity):\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=1024,\n",
    "        tools=[\n",
    "            {\n",
    "                \"name\": \"is_person_name\",\n",
    "                \"description\": \"Identify if the given entity is a person's name.\",\n",
    "                \"input_schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"entity\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The entity to check, e.g. John Doe\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"entity\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Is '{entity}' a person's name?\"}],\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Example entity to test\n",
    "entity = \"John Doe\"\n",
    "result = is_person_name(entity)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
